{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd9dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "from scipy import integrate\n",
    "import logging\n",
    "from cvxopt import matrix, solvers\n",
    "import networkx as nx\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4b222",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7341717",
   "metadata": {},
   "outputs": [],
   "source": [
    "global train_inp, train_out, val_inp, val_out, test_inp, test_out, t\n",
    "train_inp = np.load('train_inp.npy')\n",
    "train_out = np.load('train_out.npy')\n",
    "val_inp = np.load('val_inp.npy')\n",
    "val_out = np.load('val_out.npy')\n",
    "test_inp = np.load('test_inp.npy')\n",
    "test_out = np.load('test_out.npy')\n",
    "t = np.load('t.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b05fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global n, N   #n is the number of nodes, N is the number of basis \n",
    "n = 25\n",
    "N = 30\n",
    "global REG\n",
    "REG = \"MCP\"\n",
    "global op_gamma_list, Lambda_list, Gamma_list, Rho_list, Beta_list\n",
    "#best hyperparameters\n",
    "op_gamma_list = [10.]   #gamma_op\n",
    "Lambda_list = [1e-3]   #lambda\n",
    "Gamma_list = [1e-3]    #gamma\n",
    "Rho_list = [1e-2]      #rho_L\n",
    "Beta_list = [100.]    #rho_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70180445",
   "metadata": {},
   "outputs": [],
   "source": [
    "global num_train, num_val, num_test\n",
    "num_train = len(train_inp)\n",
    "num_val = len(val_inp)\n",
    "num_test = len(test_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a75165",
   "metadata": {},
   "source": [
    "# Basis Selection and Projection on basis functions with integration routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43342624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trig_basis():\n",
    "    basis = []\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            b = (1./np.sqrt(t[-1]))*np.ones(len(t))\n",
    "        else:\n",
    "            b = np.sqrt(2./t[-1])*np.cos(np.pi*i*((1./t[-1])*t))\n",
    "        basis.append(b)\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1012429",
   "metadata": {},
   "outputs": [],
   "source": [
    "global basis\n",
    "global k_mat\n",
    "basis = trig_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feae531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_coefs(x):\n",
    "    proj = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        proj[i] = inner_prod(x, basis[i])\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30246c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_prod(f, g):\n",
    "    s = 0.\n",
    "    num_t = len(f)\n",
    "    x = t\n",
    "    dx = (t[-1] - t[0])/(num_t-1)\n",
    "    fx = f*g\n",
    "    s = integrate.simps(fx, x, dx, even='avg')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa4bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_prod_2d(mat, basis_i, basis_j):\n",
    "    x = t\n",
    "    num_t = len(t)\n",
    "    dx = (t[-1] - t[0])/(num_t-1)\n",
    "    s_t = np.zeros(num_t)\n",
    "    for i in range(num_t):\n",
    "        fx = mat[:,i]*basis_j\n",
    "        s_t[i] = integrate.simps(fx, x, dx, even='avg')\n",
    "    fx = s_t*basis_i\n",
    "    s = integrate.simps(fx, x, dx, even='avg')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7afb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_kernel_encoding(exp_mat):\n",
    "    k_mat = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            k_mat[i][j] = inner_prod_2d(exp_mat, basis[i], basis[j])\n",
    "            if i!=j:\n",
    "                k_mat[j][i] = k_mat[i][j]\n",
    "    return k_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815e718",
   "metadata": {},
   "source": [
    "# Scalar and Operator-valued Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23b5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_kernel_without_M_dup(f, g, M_dup_c):\n",
    "    inner_prod_matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            inner_prod_matrix[i][j] = np.dot(f[i]-g[i], f[j]-g[j])\n",
    "            if i!=j:\n",
    "                inner_prod_matrix[j][i] = inner_prod_matrix[i][j]\n",
    "    vec_inner_prod = inner_prod_matrix.flatten()\n",
    "    r = np.zeros(int(n*(n+1)/2))\n",
    "    for i in range(int(n*(n+1)/2)):\n",
    "        c_ones = M_dup_c[i]\n",
    "        for j in c_ones:\n",
    "            if j!= -1:\n",
    "                r[i] += vec_inner_prod[j]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d469c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_inner_prod_without_M_dup(f, M_dup_c):\n",
    "    inner_prod_matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            inner_prod_matrix[i][j] = np.dot(f[i], f[j])\n",
    "            if i!=j:\n",
    "                inner_prod_matrix[j][i] = inner_prod_matrix[i][j]\n",
    "    vec_inner_prod = inner_prod_matrix.flatten()\n",
    "    r = np.zeros(int(n*(n+1)/2))\n",
    "    for i in range(int(n*(n+1)/2)):\n",
    "        c_ones = M_dup_c[i]\n",
    "        for j in c_ones:\n",
    "            if j!= -1:\n",
    "                r[i] += vec_inner_prod[j]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96517c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_inner_prod_for_z(f, g):\n",
    "    r = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        r[i] = np.dot(f[i]-g[i], f[i]-g[i])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09dfaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_kernel_calc(Gamma, R, vech_L, i, j):\n",
    "    return i,j,np.exp(-Gamma*np.dot(R[i][j],vech_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057b00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_kernel_calc_normal(Gamma, R, vech_L, D, Z, i, j):\n",
    "    return np.exp(-Gamma*(np.dot(R[i][j],vech_L) + np.dot(Z[i][j], D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b41a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_G(vech_L, R, Gamma, D, Z):\n",
    "    G = np.zeros((num_train,num_train))\n",
    "    for i in range(num_train):\n",
    "        for j in range(i, num_train):\n",
    "            G[i][j] = scalar_kernel_calc_normal(Gamma, R, vech_L, D, Z, i, j)\n",
    "            if i != j:\n",
    "                G[j][i] = G[i][j]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028bab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_kernel(z, op_gamma):\n",
    "    y = np.zeros(len(basis[0]))\n",
    "    for i in range(len(basis)):\n",
    "        y += z[i]*basis[i]\n",
    "    one = np.ones(len(y))\n",
    "    X = np.zeros(y.shape)\n",
    "    for i in range(len(y)):\n",
    "        s = t\n",
    "        dx = t[-1]/(len(y)-1)\n",
    "        f = np.multiply(np.exp(-op_gamma*np.abs(t[i]*one-s)),y)\n",
    "        X[i] = integrate.simps(f, s, dx, even='avg')\n",
    "    fX = get_proj_coefs(X)\n",
    "    return fX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b718c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_kernel_modified(z, k_mat):\n",
    "    return np.dot(k_mat,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae7816b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_kernel_exp(op_gamma):\n",
    "    exp_mat = np.zeros((len(t),len(t)))\n",
    "    for i in range(len(t)):\n",
    "        for j in range(len(t)):\n",
    "            exp_mat[i][j] = np.exp(-op_gamma*(np.abs(t[i]-t[j])))\n",
    "    return exp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af8a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_K_normal(u, op_gamma):\n",
    "    n1 = len(u)\n",
    "    K = []\n",
    "    for i in range(n1):\n",
    "        K.append(op_kernel(u[i], op_gamma))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0bdefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_K_normal_modified(u, k_mat):\n",
    "    n1 = len(u)\n",
    "    K = np.zeros((n1, N))\n",
    "    for i in range(n1):\n",
    "        K[i] = op_kernel_modified(u[i], k_mat)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b53170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_dot_A(G, v, op_gamma, Lambda):\n",
    "    n1 = len(v)\n",
    "    Av = np.zeros(v.shape)\n",
    "    K = op_K_normal(v, op_gamma)\n",
    "    for i in range(n1):\n",
    "        X = 0.* v[0]\n",
    "        for j in range(n1):\n",
    "            if i == j:\n",
    "                X += G[i,j]*(K[j]) + Lambda*(v[j])\n",
    "            else:\n",
    "                X += G[i,j]*(K[j])\n",
    "        Av[i] = X\n",
    "    return Av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ef2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_dot_A_modified(G, v, Lambda, k_mat):\n",
    "    n1 = len(v)\n",
    "    Av = np.zeros(v.shape)\n",
    "    K = op_K_normal_modified(v, k_mat)\n",
    "    for i in range(n1):\n",
    "        X = 0.* v[0]\n",
    "        for j in range(n1):\n",
    "            if i == j:\n",
    "                X += G[i][j]*(K[j]) + Lambda*(v[j])\n",
    "            else:\n",
    "                X += G[i][j]*(K[j])\n",
    "        Av[i] = X\n",
    "    return Av"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225a9c6",
   "metadata": {},
   "source": [
    "# OpMINRES related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5db3abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LanczosStep(G, v1, v0, beta1, Lambda):\n",
    "    p = op_dot_A_modified(G, v1, Lambda, k_mat)\n",
    "    alpha = np.sum(np.multiply(v1,p))\n",
    "    p = p - alpha*v1\n",
    "    v2 = p - beta1*v0\n",
    "    beta2 = np.linalg.norm(v2)\n",
    "    if (beta2 != 0):\n",
    "        v2 = (1./beta2)*v2\n",
    "    return alpha, beta2, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "866c1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymOrtho(a, b):\n",
    "    if (b == 0):\n",
    "        s = 0\n",
    "        r = np.abs(a)\n",
    "        if (a == 0):\n",
    "            c = 1\n",
    "        else:\n",
    "            c = np.sign(a)\n",
    "    elif (a == 0):\n",
    "        c = 0\n",
    "        s = np.sign(b)\n",
    "        r = np.abs(b)\n",
    "    elif (np.abs(b) > np.abs(a)):\n",
    "        tau = a/b\n",
    "        s = np.sign(b)/np.sqrt(1 + tau**2)\n",
    "        c = s*tau\n",
    "        r = b/s\n",
    "    elif (np.abs(a) > np.abs(b)):\n",
    "        tau = b/a\n",
    "        c = np.sign(a)/np.sqrt(1 + tau**2)\n",
    "        s = c*tau\n",
    "        r = a/c\n",
    "    return c, s, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cff2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpMINRES(G, b, maxiter, tol, Lambda):\n",
    "    beta1 = np.linalg.norm(b)\n",
    "    n = len(b)\n",
    "    v0 = np.zeros((n,N))\n",
    "    v1 = (1./beta1)*b\n",
    "    phi0 = beta1\n",
    "    phi1 = beta1\n",
    "    phi00 = beta1\n",
    "    tau = beta1\n",
    "    chi = 0\n",
    "    delta1_1 = 0\n",
    "    epsilon1_1 = 0\n",
    "    c0 = -1\n",
    "    s0 = 0\n",
    "    d1 = np.zeros((n,N))\n",
    "    d0 = np.zeros((n,N))\n",
    "    x0 = np.zeros((n,N))\n",
    "    k = 1\n",
    "    x = []\n",
    "    phi = []\n",
    "    psi = []\n",
    "    chi1 = []\n",
    "    while(k <= maxiter and phi1/phi00 > tol):\n",
    "        alpha, beta2, v2 = LanczosStep(G, v1, v0, beta1, Lambda)\n",
    "        #last left orthogonaization on middle two entries in last column of T_k\n",
    "        delta1_2 = c0*delta1_1 + s0*alpha\n",
    "        gamma1_1 = s0*delta1_1 - c0*alpha\n",
    "        #last left orthogonalization to produce first two entries of T_k+1e_k+1\n",
    "        epsilon2_1 = s0*beta2\n",
    "        delta2_1 = -c0*beta2\n",
    "        #current left orthogonalization to zero out beta_k+1\n",
    "        c1, s1, gamma1_2 = SymOrtho(gamma1_1, beta2)\n",
    "        #right-hand side, residual norms\n",
    "        tau = c1*phi0\n",
    "        phi1 = s1*phi0\n",
    "        psi0 = phi0*np.sqrt(gamma1_1**2 + delta2_1**2)\n",
    "        if (gamma1_2 != 0):\n",
    "            d2 = (1./gamma1_2)*(v1 - delta1_2*d1 - epsilon1_1*d0)\n",
    "            x1 = x0 + tau*d2\n",
    "            chi = np.linalg.norm(x1)\n",
    "        k = k + 1\n",
    "        v0 = v1\n",
    "        v1 = v2\n",
    "        beta1 = beta2\n",
    "        c0 = c1\n",
    "        s0 = s1\n",
    "        phi0 = phi1\n",
    "        delta1_1 = delta2_1\n",
    "        epsilon1_1 = epsilon2_1\n",
    "        x0 = x1\n",
    "        d0 = d1\n",
    "        d1 = d2\n",
    "        x.append(x0)\n",
    "        phi.append(phi0)\n",
    "        psi.append(phi0*np.sqrt(gamma1_1**2 + delta2_1**2))\n",
    "        chi1.append(chi)\n",
    "    return x, phi, psi, chi1, k-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f0285",
   "metadata": {},
   "source": [
    "#  M_dup, A, B, C computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75846429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_A_with_C(n):\n",
    "    A = np.zeros((n+1,int(n*(n+1)/2)))\n",
    "    l = 0\n",
    "    for i in range(n):\n",
    "        A[i][l:l+n-i] = np.ones(n-i)\n",
    "        if(i == n-1):\n",
    "            A[i][int(n*(n+1)/2)-1] = 1.\n",
    "        k = 0\n",
    "        for j in range(i):\n",
    "            A[i][k+i] = 1.\n",
    "            k += n - j -1\n",
    "        l += n-i\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n-i):\n",
    "            if j == 0:\n",
    "                A[-1,k] = 1\n",
    "            k += 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc8fae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_determine_M_dup_c_1(n, i):\n",
    "    one1 = []\n",
    "    n0 = n\n",
    "    i0 = i\n",
    "    q0 = 0\n",
    "    r0 = 1\n",
    "    for i in range(n):\n",
    "        q = int(i0/n0)\n",
    "        r = i0 % n0\n",
    "        if q == 0:\n",
    "            if r == 0:\n",
    "                one1.append(q0)\n",
    "                return one1\n",
    "            else:\n",
    "                one1.append(q0 + r)\n",
    "                one1.append(q0 + r*n)\n",
    "                return one1\n",
    "        else:\n",
    "            i0 -= n0\n",
    "            n0 -= 1\n",
    "            q0 += n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16c36807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_A_r_1(n, i):\n",
    "    one1 = []\n",
    "    pos = i\n",
    "    skip = n-1\n",
    "    for j in range(n):\n",
    "        if j < i:\n",
    "            one1.append(pos)\n",
    "            pos += skip\n",
    "            skip -= 1\n",
    "        else:\n",
    "            one1.append(pos)\n",
    "            pos += 1\n",
    "    return one1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57622427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_A_c_1(n, i):\n",
    "    one1 = []\n",
    "    pos = 0\n",
    "    skip = n\n",
    "    row = 0\n",
    "    m = 1\n",
    "    if i==0:\n",
    "        one1.append(0)\n",
    "        return one1\n",
    "    else:\n",
    "        for j in range(1,i+1):\n",
    "            if j==skip:\n",
    "                pos += 1\n",
    "                if j==i:\n",
    "                    one1.append(pos)\n",
    "                    return one1\n",
    "                row = pos\n",
    "                skip += n-m\n",
    "                m += 1\n",
    "            else:\n",
    "                row += 1\n",
    "                if j==i:\n",
    "                    one1.append(pos)\n",
    "                    one1.append(row)\n",
    "                    return one1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df54edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_B(n):\n",
    "    B = np.zeros((int(n*(n-1)/2),int(n*(n+1)/2)))\n",
    "    if (n == 2):\n",
    "        B = [1]\n",
    "    else:\n",
    "        j = n\n",
    "        k = 1\n",
    "        l = 0\n",
    "        for i in range(int(n*(n-1)/2)):\n",
    "            if(k == j):\n",
    "                k = 1\n",
    "                l += j\n",
    "                j -= 1\n",
    "            B[i][l+k] = 1.\n",
    "            k += 1\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b997fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_C(n):\n",
    "    C = np.zeros(int(n*(n+1)/2))\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n-i):\n",
    "            if j == 0:\n",
    "                C[k] = 1\n",
    "            k += 1\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9bc7b",
   "metadata": {},
   "source": [
    "# R matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8c3bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_mat(t_inp, M_dup_c):\n",
    "    R = np.zeros((num_train,num_train,int(n*(n+1)/2)))\n",
    "    for i in range(num_train):\n",
    "        for j in range(i,num_train):\n",
    "            R[i][j] = scalar_kernel_without_M_dup(t_inp[i], t_inp[j], M_dup_c)\n",
    "            if i!=j:\n",
    "                R[j][i] = R[i][j]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f444319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_l_loss(t_inp, M_dup_c):\n",
    "    R = np.zeros((num_train,int(n*(n+1)/2)))\n",
    "    for i in range(num_train):\n",
    "        R[i] = scalar_inner_prod_without_M_dup(t_inp[i], M_dup_c)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40619959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_mat(t_inp):\n",
    "    Z = np.zeros((num_train, num_train, n))\n",
    "    for i in range(num_train):\n",
    "        for j in range(i, num_train):\n",
    "            Z[i][j] = scalar_inner_prod_for_z(t_inp[i], t_inp[j])\n",
    "            if i!=j:\n",
    "                Z[j][i] = Z[i][j]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d7d37",
   "metadata": {},
   "source": [
    "# Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df118efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_mcp(x):\n",
    "    x = -x\n",
    "    hx = np.zeros(int(n*(n+1)/2))\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] >= 0):\n",
    "            if (x[i] <= Gamma_reg*Lambda_reg):\n",
    "                hx[i] = Lambda_reg - x[i]/Gamma_reg\n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddebb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcp_reg(x, C):\n",
    "    diag = np.ones(int(n*(n+1)/2)) - C\n",
    "    h = h_mcp(x) \n",
    "    regularizer_grad = -np.multiply(diag, h)\n",
    "    return regularizer_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3de6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_scad(x):\n",
    "    x = -x\n",
    "    hx = np.zeros(int(n*(n+1)/2))\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] >= 0):\n",
    "            if (x[i] <= Lambda_reg):\n",
    "                hx[i] = Lambda_reg\n",
    "            elif(x[i] <= Gamma_reg*Lambda_reg):\n",
    "                hx[i] = (Gamma_reg*Lambda_reg - x[i])/(Gamma_reg - 1)\n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "955c2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scad_reg(x, C):\n",
    "    diag = np.ones(int(n*(n+1)/2)) - C\n",
    "    h = h_scad(x) \n",
    "    regularizer_grad = -np.multiply(diag, h)\n",
    "    return regularizer_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d35255",
   "metadata": {},
   "source": [
    "# vech(L) <--> vec(L) conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f1f645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vech_to_vec(vech_L):\n",
    "    m = len(vech_L)\n",
    "    n = int((np.sqrt(1 + 8*m) - 1)/2)\n",
    "    L = np.zeros((n,n))\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "        L[i,i:] = vech_L[k:k+n-i]\n",
    "        L[:,i] = L[i,:]\n",
    "        k = k + n -i\n",
    "    vec_L = L.flatten()\n",
    "    return vec_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c4e8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_vech(vec_L):\n",
    "    m = len(vec_L)\n",
    "    sq_m = int(np.sqrt(m))\n",
    "    n = int((np.sqrt(m)*(np.sqrt(m)+1))/2)\n",
    "    vech_L = np.zeros(n)\n",
    "    k = 0\n",
    "    l = 0\n",
    "    for i in range(sq_m):\n",
    "        vech_L[k:k+sq_m-i] = vec_L[l+i:l+sq_m]\n",
    "        k = k + sq_m - i\n",
    "        l = l + sq_m\n",
    "    return vech_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a9a5c",
   "metadata": {},
   "source": [
    "# Projection of Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dacc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sum_proj_a(z, lambda_proj, mu_proj, ones_r):#not used #check for parallelization\n",
    "    S = 0.\n",
    "    for i in ones_r:\n",
    "        S1 = 0.\n",
    "        Ai_c_ones = determine_A_c_1(n, i)#check for n, needs to be passed \n",
    "        for p in Ai_c_ones:\n",
    "            S1 += lambda_proj[p]\n",
    "        S2 = 0.\n",
    "        Bi_c_one = determine_B_c_1(n, i)\n",
    "        if Bi_c_one != -1:\n",
    "            S2 = mu_proj[Bi_c_one]\n",
    "        S += (z[i]- S1 - S2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db738647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sum_proj_b(z, lambda_proj, mu_proj, ones_r):#not used #check for parallelization\n",
    "    S1 = 0.\n",
    "    S2 = 0.\n",
    "    Ai_c_ones = determine_A_c_1(n, ones_r)\n",
    "    for p in Ai_c_ones:\n",
    "        S1 += lambda_proj[p]\n",
    "    Bi_c_one = determine_B_c_1(n, ones_r)\n",
    "    if Bi_c_one != -1:\n",
    "        S2 = mu_proj[Bi_c_one]\n",
    "    S = (z[ones_r]- S1 - S2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28366c7",
   "metadata": {},
   "source": [
    "# Gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b0ca510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_setup(Op_k, y, u):\n",
    "    N1 = len(y)\n",
    "    #R_x = np.zeros((N1,N1))\n",
    "    Op_kk = np.zeros((N1,N1))\n",
    "    y_k = np.zeros((N1,N1))\n",
    "    k_u = np.zeros((N1,N1))\n",
    "    for i in range(N1):\n",
    "        for j in range(N1):\n",
    "            if j>=i:\n",
    "                Op_kk[i][j] = np.dot(Op_k[i], Op_k[j])\n",
    "                if i!=j:\n",
    "                    Op_kk[j][i] = Op_kk[i][j]\n",
    "            y_k[i][j] = np.dot(y[i], Op_k[j])\n",
    "            k_u[i][j] = np.dot(Op_k[i], u[j])\n",
    "    return Op_kk, y_k, k_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b00b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_J(x, y, u, R, R_l, C, Gamma, Lambda, Rho, m_trace, Op_kk, y_k, k_u, D, Z):\n",
    "    N1 = len(y)\n",
    "    S1 = np.zeros(int(n*(n+1)/2))\n",
    "    S2 = np.zeros(int(n*(n+1)/2))\n",
    "    S3 = np.zeros(int(n*(n+1)/2))\n",
    "    S4 = np.zeros(int(n*(n+1)/2))\n",
    "    R_x = np.zeros((N1,N1))\n",
    "    for i in range(N1):\n",
    "        for j in range(N1):\n",
    "            R_x[i][j] = np.dot(R[i][j],x) + np.dot(Z[i][j], D)\n",
    "    for i in range(N1):\n",
    "        for j in range(N1):\n",
    "            for k in range(N1):\n",
    "                S2 = S2 +  np.exp(-Gamma*(R_x[i][j]+R_x[i][k]))*Op_kk[j][k]*(R[i][j]+R[i][k]).T\n",
    "            S1 = S1 + np.exp(-Gamma*R_x[i][j])*y_k[i][j]*R[i][j].T\n",
    "            S3 = S3 + np.exp(-Gamma*R_x[i][j])*k_u[i][j]*R[i][j].T\n",
    "        S4 = S4 + R_l[i].T\n",
    "    S = 2*Gamma*S1 - Gamma*S2 - Lambda*Gamma*S3 + Rho*S4\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a677379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_J_D(x, y, u, R, Gamma, Lambda, Beta, Op_kk, y_k, k_u, D, Z):\n",
    "    N1 = len(y)\n",
    "    S1 = np.zeros(n)\n",
    "    S2 = np.zeros(n)\n",
    "    S3 = np.zeros(n)\n",
    "    R_x = np.zeros((N1,N1))\n",
    "    Z_D = np.zeros((N1,N1))\n",
    "    for i in range(N1):\n",
    "        for j in range(N1):\n",
    "            R_x[i][j] = np.dot(R[i][j],x)\n",
    "            Z_D[i][j] = np.dot(Z[i][j], D)\n",
    "    for i in range(N1):\n",
    "        for j in range(N1):\n",
    "            for k in range(N1):\n",
    "                S2 = S2 + np.exp(-Gamma*(R_x[i][j]+R_x[i][k]+(Z_D[i][j]+Z_D[i][k])))*Op_kk[j][k]*(Z[i][j]+Z[i][k]).T\n",
    "            S1 = S1 + np.exp(-Gamma*(R_x[i][j]+ Z_D[i][j]))*y_k[i][j]*Z[i][j].T\n",
    "            S3 = S3 + np.exp(-Gamma*(R_x[i][j]+ Z_D[i][j]))*k_u[i][j]*Z[i][j].T\n",
    "    S = 2*Gamma*S1 - Gamma*S2 - Lambda*Gamma*S3 + 2*Beta*D\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124904d1",
   "metadata": {},
   "source": [
    "# Test & Loss Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d425bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_test(t_inp, t_test, M_dup_c):\n",
    "    N1 = len(t_inp)\n",
    "    N2 = len(t_test)\n",
    "    test_R = np.zeros((N1,N2,int(n*(n+1)/2)))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            test_R[i][j] = scalar_kernel_without_M_dup(t_inp[i], t_test[j], M_dup_c)\n",
    "    return test_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57e3f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_test(t_inp, t_test):\n",
    "    N1 = len(t_inp)\n",
    "    N2 = len(t_test)\n",
    "    test_Z = np.zeros((N1,N2,n))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            test_Z[i][j] = scalar_inner_prod_for_z(t_inp[i], t_test[j])\n",
    "    return test_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70f4a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(test_inp_B, test_out_B, train_inp_B, vech_L, u, D, M_dup_c, Gamma, k_mat):\n",
    "    n_test = len(test_inp_B)\n",
    "    n_train = len(train_inp_B)\n",
    "    test_R = R_test(train_inp_B, test_inp_B, M_dup_c)\n",
    "    test_Z = Z_test(train_inp_B, test_inp_B)\n",
    "    Op_k = op_K_normal_modified(u, k_mat)\n",
    "    pred_test_out = 0.*test_out_B\n",
    "    loss = 0.\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            pred_test_out[i] = pred_test_out[i] + np.exp(-Gamma*(np.dot(test_R[j][i],vech_L)+np.dot(test_Z[j][i],D)))*Op_k[j]\n",
    "        loss += np.linalg.norm(pred_test_out[i]-test_out_B[i])**2\n",
    "    return loss/n_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cbfae",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9213d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(test_inp_B, test_out_B, train_inp_B, vech_L, u, D, no_of_plots, title, Gamma, k_mat):\n",
    "    n_test = len(test_inp_B)\n",
    "    n_train = len(train_inp_B)\n",
    "    test_R = R_test(train_inp_B, test_inp_B, M_dup_c)\n",
    "    test_Z = Z_test(train_inp_B, test_inp_B)\n",
    "    Op_k = op_K_normal_modified(u, k_mat)\n",
    "    pred_test_out = 0.*test_out_B\n",
    "    loss = 0.\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            pred_test_out[i] = pred_test_out[i] + np.exp(-Gamma*(np.dot(test_R[j][i],vech_L)+np.dot(test_Z[j][i],D)))*Op_k[j]\n",
    "        loss += np.linalg.norm(pred_test_out[i]-test_out_B[i])**2\n",
    "    pred_test = []\n",
    "    actual_test = []\n",
    "    for i in range(n_test):\n",
    "        pred = np.zeros(len(basis[0]))\n",
    "        act = np.zeros(len(basis[0]))\n",
    "        for j in range(N):\n",
    "            pred = pred + pred_test_out[i][j]*basis[j]\n",
    "            act = act + test_out_B[i][j]*basis[j]\n",
    "        actual_test.append(act)\n",
    "        pred_test.append(pred)\n",
    "    fig, axes = plt.subplots(int(no_of_plots/4),4, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    fig.suptitle(title)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.plot(t, pred_test[i], t, actual_test[i])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels=['Predicted', 'Actual'])\n",
    "    plt.show()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa394b71",
   "metadata": {},
   "source": [
    "# Main Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e9fcf38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup complete!\n",
      "Iteration: op_gamma: 10.0  Lambda: 0.001  Gamma: 0.001  Rho: 0.01  Beta: 100.0\n",
      "===================================================================\n",
      "i, j, l, i_D : ( 50 , 1 , 0 , 6 )\n",
      "Algo finished\n",
      "Training loss after complete iteration:  0.6619863357913731\n",
      "Validation loss after complete iteration:  1.5495433764557323\n",
      "==============================================================================\n",
      "Best op_gamma:  10.0\n",
      "Best Lambda:  0.001\n",
      "Best Gamma:  0.001\n",
      "Best Rho:  0.01\n",
      "Best Beta:  100.0\n",
      "Best validation error value: 1.5495433764557323\n",
      "Best training error value: 0.6619863357913731\n",
      "(0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "m_trace = np.ceil(n/2)\n",
    "Lambda_reg = 0.5\n",
    "Gamma_reg = 1.\n",
    "start_eta = 1e-4\n",
    "end_eta = 1e-9\n",
    "E1 = 1e-3\n",
    "E2 = 1e-3\n",
    "E3 = 1e-3\n",
    "E_D = 1e-3\n",
    "start_eta_D = 1e-4\n",
    "end_eta_D = 1e-9\n",
    "train_out_B = np.zeros((len(train_out),N))\n",
    "for s in range(len(train_out)):\n",
    "    train_out_B[s] = get_proj_coefs(train_out[s])\n",
    "train_inp_B = np.zeros((len(train_out), n, N))\n",
    "for s1 in range(num_train):\n",
    "    for s2 in range(len(train_inp[0])):\n",
    "        train_inp_B[s1][s2] = get_proj_coefs(train_inp[s1][s2])\n",
    "val_out_B = np.zeros((len(val_out),N))\n",
    "for s in range(len(val_out)):\n",
    "    val_out_B[s] = get_proj_coefs(val_out[s])\n",
    "val_inp_B = np.zeros((len(val_out), n, N))\n",
    "for s1 in range(num_val):\n",
    "    for s2 in range(len(val_inp[0])):\n",
    "        val_inp_B[s1][s2] = get_proj_coefs(val_inp[s1][s2])\n",
    "test_out_B = np.zeros((len(test_out),N))\n",
    "for s in range(len(test_out)):\n",
    "    test_out_B[s] = get_proj_coefs(test_out[s])\n",
    "test_inp_B = np.zeros((len(test_out), n, N))\n",
    "for s1 in range(num_test):\n",
    "    for s2 in range(len(test_inp[0])):\n",
    "        test_inp_B[s1][s2] = get_proj_coefs(test_inp[s1][s2])\n",
    "np.save('train_inp_B_12.npy', train_inp_B)\n",
    "np.save('train_out_B_12.npy', train_out_B)\n",
    "np.save('val_inp_B_12.npy', val_inp_B)\n",
    "np.save('val_out_B_12.npy', val_out_B)\n",
    "np.save('test_inp_B_12.npy', test_inp_B)\n",
    "np.save('test_out_B_12.npy', test_out_B)\n",
    "np.save('t.npy', t)\n",
    "A = determine_A_with_C(n)\n",
    "B = determine_B(n)\n",
    "C = determine_C(n)\n",
    "M_dup_c = np.zeros((int(n*(n+1)/2),2))\n",
    "for s1 in range(int(n*(n+1)/2)):\n",
    "    col = np.asarray(fast_determine_M_dup_c_1(n, s1))\n",
    "    if len(col) == 1:\n",
    "        M_dup_c[s1][0] = col[0]\n",
    "        M_dup_c[s1][1] = -1\n",
    "    else:\n",
    "        M_dup_c[s1] = col\n",
    "M_dup_c = M_dup_c.astype(int)\n",
    "R = R_mat(train_inp_B, M_dup_c)\n",
    "np.save('R_12', R)\n",
    "R_l = R_l_loss(train_inp_B, M_dup_c)\n",
    "np.save('R_l_12', R_l)\n",
    "Z = Z_mat(train_inp_B)\n",
    "print(\"setup complete!\")\n",
    "solvers.options['show_progress'] = False\n",
    "val_err_mat = 10000*np.ones((len(op_gamma_list),len(Lambda_list),len(Gamma_list),len(Rho_list),len(Beta_list)))\n",
    "train_err_mat = 10000*np.ones((len(op_gamma_list),len(Lambda_list),len(Gamma_list),len(Rho_list),len(Beta_list)))\n",
    "vech_L_list = []\n",
    "u_list = []\n",
    "D_list = []\n",
    "i_op = 0\n",
    "for op_gamma in op_gamma_list:\n",
    "    i_lambda = 0\n",
    "    k_mat = exp_kernel_encoding(op_kernel_exp(op_gamma))\n",
    "    for Lambda in Lambda_list:\n",
    "        i_gamma = 0\n",
    "        for Gamma in Gamma_list:\n",
    "            i_rho = 0\n",
    "            for Rho in Rho_list:\n",
    "                i_beta = 0\n",
    "                for Beta in Beta_list:\n",
    "                    L = np.eye(n)\n",
    "                    D = np.ones(n)\n",
    "                    for s in range(n):\n",
    "                        L[s][s] = m_trace/n\n",
    "                        for s1 in range(s+1,n):\n",
    "                            L[s][s1] = -L[s][s]/(n-1)\n",
    "                            L[s1][s] =  L[s][s1]\n",
    "                    vec_L = L.flatten()\n",
    "                    vech_L = vec_to_vech(vec_L)\n",
    "                    u_error = E1+1\n",
    "                    patience = 5\n",
    "                    i = 1\n",
    "                    print(\"Iteration: op_gamma:\",op_gamma,\" Lambda:\", Lambda,\" Gamma:\", Gamma,\" Rho:\", Rho,\" Beta:\", Beta)\n",
    "                    print(\"===================================================================\")\n",
    "                    #main_loop\n",
    "                    while(u_error >= E1 and i<=50):\n",
    "                        G = scalar_G(vech_L, R, Gamma, D, Z)\n",
    "                        u, phi, psi, chi, k = OpMINRES(G, train_out_B, 1000, 1e-3, Lambda)\n",
    "                        u_ = u[k-1]\n",
    "                        Op_k = op_K_normal_modified(u_, k_mat)\n",
    "                        j = 1\n",
    "                        vech_L_error = E2+1\n",
    "                        if i==1 and j == 1:\n",
    "                            vech_L_ = (m_trace/(n*(n-1)))*np.ones(int(n*(n+1)/2))\n",
    "                            pos = 0\n",
    "                            for s in range(n):\n",
    "                                vech_L_[pos+s] = m_trace/n\n",
    "                                pos += n-s-1\n",
    "                        patience_count = 0\n",
    "                        Op_kk, y_k, k_u = gradient_setup(Op_k, train_out_B, u_)\n",
    "                        eta = start_eta\n",
    "                        #vech(L) loop\n",
    "                        while(vech_L_error >= E2 and j<=100):\n",
    "                            grad_J = gradient_J(vech_L_, train_out_B, u_, R, R_l, C, Gamma, Lambda, Rho, m_trace, Op_kk, y_k, k_u, D, Z)\n",
    "                            x_k = vech_L_ - eta*grad_J\n",
    "                            l = 0\n",
    "                            vech_L_reg_error = E3 + 1\n",
    "                            if REG == \"None\":\n",
    "                                m_trace_0_vec = np.zeros(n+1)\n",
    "                                m_trace_0_vec[-1] = m_trace\n",
    "                                Q = matrix(2*np.eye(int(n*(n+1)/2)))\n",
    "                                p = matrix(-2*x_k)\n",
    "                                G = matrix(B)\n",
    "                                h = matrix(np.zeros(int(n*(n-1)/2)))\n",
    "                                A = matrix(A)\n",
    "                                b = matrix(m_trace_0_vec)\n",
    "                                sol = solvers.qp(Q, p, G, h, A, b)\n",
    "                                vech_L = np.array(sol['x'])\n",
    "                                vech_L = np.squeeze(vech_L)\n",
    "                            else:\n",
    "                                while(vech_L_reg_error >= E3 and l <= 1000):\n",
    "                                    if REG == \"MCP\":\n",
    "                                        h = mcp_reg(vech_L_, C)\n",
    "                                        p = matrix(-2*x_k + h)\n",
    "                                    elif REG == \"SCAD\":\n",
    "                                        h = scad_reg(vech_L_, C)\n",
    "                                        p = matrix(-2*x_k + h)\n",
    "                                    m_trace_0_vec = np.zeros(n+1)\n",
    "                                    m_trace_0_vec[-1] = m_trace\n",
    "                                    Q = matrix(2*np.eye(int(n*(n+1)/2)))     #2 included to balance h term\n",
    "                                    G = matrix(B)\n",
    "                                    h = matrix(np.zeros(int(n*(n-1)/2)))\n",
    "                                    A = matrix(A)\n",
    "                                    b = matrix(m_trace_0_vec)\n",
    "                                    sol = solvers.qp(Q, p, G, h, A, b)\n",
    "                                    vech_L = np.array(sol['x'])\n",
    "                                    vech_L = np.squeeze(vech_L)\n",
    "                                    vech_L_reg_error = np.linalg.norm(vech_L - vech_L_)\n",
    "                                    vech_L_ = vech_L\n",
    "                                    l += 1\n",
    "                            vech_L_error = np.linalg.norm(vech_L-vech_L_)\n",
    "                            vech_L_ = vech_L\n",
    "                            if j%5 == 0:\n",
    "                                eta = eta/2\n",
    "                            if eta < end_eta:\n",
    "                                eta = end_eta\n",
    "                            j += 1\n",
    "                        i_D = 1\n",
    "                        D_error = E_D + 1\n",
    "                        D_ = D\n",
    "                        if i==1 and j==1 and k==1:\n",
    "                            D_ = np.ones(n)\n",
    "                        eta_D = start_eta_D\n",
    "                        #vech(D) loop\n",
    "                        while(D_error >= E_D and i_D <= 100):\n",
    "                            grad_J_D = gradient_J_D(vech_L, train_out_B, u_, R, Gamma, Lambda, Beta, Op_kk, y_k, k_u, D_, Z)\n",
    "                            D = D_ - eta_D*grad_J_D\n",
    "                            D[D < 0.] = 0.\n",
    "                            D_error = np.linalg.norm(D-D_)\n",
    "                            D_ = D\n",
    "                            if i_D%5 == 0:\n",
    "                                eta_D = eta_D/2\n",
    "                            if eta_D < end_eta_D:\n",
    "                                eta_D = end_eta_D\n",
    "                            i_D += 1\n",
    "                        if i == 1:\n",
    "                            u_error = E1 + 1\n",
    "                        else:\n",
    "                            u_error = np.linalg.norm(u_-u_1)\n",
    "                        u_1 = u_\n",
    "                        i += 1\n",
    "                    print(\"i, j, l, i_D : (\", i-1,\",\", j-1,\",\",l-1,\",\",i_D-1,\")\")\n",
    "                    print(\"Algo finished\")\n",
    "                    loss = test_loss(train_inp_B, train_out_B, train_inp_B, vech_L, u_, D, M_dup_c, Gamma, k_mat)\n",
    "                    print(\"Training loss after complete iteration: \", loss)\n",
    "                    val_l = test_loss(val_inp_B, val_out_B, train_inp_B, vech_L, u_, D, M_dup_c, Gamma, k_mat)\n",
    "                    print(\"Validation loss after complete iteration: \", val_l)\n",
    "                    D_list.append(D)\n",
    "                    vech_L_list.append(vech_L)\n",
    "                    u_list.append(u_)\n",
    "                    train_err_mat[i_op][i_lambda][i_gamma][i_rho][i_beta] = loss\n",
    "                    val_err_mat[i_op][i_lambda][i_gamma][i_rho][i_beta] = val_l\n",
    "                    i_beta += 1\n",
    "                i_rho += 1\n",
    "            i_gamma += 1\n",
    "        i_lambda += 1\n",
    "    i_op += 1\n",
    "err_mat_argmin = np.unravel_index(val_err_mat.argmin(), val_err_mat.shape)\n",
    "print(\"==============================================================================\")\n",
    "print(\"Best op_gamma: \", op_gamma_list[err_mat_argmin[0]])\n",
    "print(\"Best Lambda: \", Lambda_list[err_mat_argmin[1]])\n",
    "print(\"Best Gamma: \", Gamma_list[err_mat_argmin[2]])\n",
    "print(\"Best Rho: \", Rho_list[err_mat_argmin[3]])\n",
    "print(\"Best Beta: \", Beta_list[err_mat_argmin[4]])\n",
    "print(\"Best validation error value:\", val_err_mat[err_mat_argmin])\n",
    "print(\"Best training error value:\", train_err_mat[err_mat_argmin])\n",
    "print(err_mat_argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1739712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[1.54954338]]]]]\n",
      "10.0\n",
      "0.001\n",
      "0.001\n",
      "0.01\n",
      "100.0\n",
      "(0, 0, 0, 0, 0)\n",
      "0\n",
      "1.5495433764557323\n",
      "Best validation error:  1.5495433764557323\n",
      "Best training error:  0.6619863357913731\n",
      "Best test error:  1.2155185399285924\n"
     ]
    }
   ],
   "source": [
    "print(val_err_mat)\n",
    "print(op_gamma_list[err_mat_argmin[0]])\n",
    "print(Lambda_list[err_mat_argmin[1]])\n",
    "print(Gamma_list[err_mat_argmin[2]])\n",
    "print(Rho_list[err_mat_argmin[3]])\n",
    "print(Beta_list[err_mat_argmin[4]])\n",
    "print(err_mat_argmin)\n",
    "best_index = err_mat_argmin[0]*(len(Lambda_list)*len(Gamma_list)*len(Rho_list)*len(Beta_list))+err_mat_argmin[1]*(len(Gamma_list)*len(Rho_list)*len(Beta_list))+err_mat_argmin[2]*(len(Rho_list)*len(Beta_list))+err_mat_argmin[3]*(len(Beta_list))+err_mat_argmin[4]\n",
    "print(best_index)\n",
    "val_err_mat_flat = val_err_mat.flatten()\n",
    "print(val_err_mat_flat[best_index])\n",
    "best_D = D_list[best_index]\n",
    "best_vech_L = vech_L_list[best_index]\n",
    "best_u = u_list[best_index]\n",
    "best_Gamma = Gamma_list[err_mat_argmin[2]]\n",
    "best_op_gamma = op_gamma_list[err_mat_argmin[0]]\n",
    "print(\"Best validation error: \",val_err_mat[err_mat_argmin])\n",
    "print(\"Best training error: \", train_err_mat[err_mat_argmin])\n",
    "k_mat = exp_kernel_encoding(op_kernel_exp(best_op_gamma))\n",
    "test_err = test_loss(test_inp_B, test_out_B, train_inp_B, best_vech_L, best_u, best_D, M_dup_c, best_Gamma, k_mat)\n",
    "print(\"Best test error: \", test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38a86f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('best_D_sparse_opminres-l-d_160_40_40.npy', best_D)\n",
    "np.save('best_vech_L_sparse_opminres-l-d_160_40_40.npy', best_vech_L)\n",
    "np.save('best_u_sparse_opminres-l-d_160_40_40.npy', best_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a22f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "#trace\n",
    "trace = 0.\n",
    "j = 0\n",
    "for i in range(n):\n",
    "    trace += vech_L[j]\n",
    "    j += n - i\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b53a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1474949/1585258999.py:28: UserWarning: You have mixed positional and keyword arguments, some input may be discarded.\n",
      "  fig.legend(handles, labels=['Predicted', 'Actual'])\n"
     ]
    }
   ],
   "source": [
    "plot_predictions(test_inp_B, test_out_B, train_inp_B, best_vech_L, best_u, best_D, 20, 'Test Data', best_Gamma, k_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_L = vech_to_vec(best_vech_L)\n",
    "L = vec_L.reshape((n,n))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d893e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_graph_with_thresh(vech_L, c_num):\n",
    "    vec_L = vech_to_vec(vech_L)\n",
    "    L = vec_L.reshape((n,n))\n",
    "    W = np.diag(np.diag(L)) - L\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(W)):\n",
    "        G.add_node(i+1)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if W[i][j] > 0:\n",
    "                G.add_edge(i+1, j+1, weight=np.log10(W[i][j]))\n",
    "    plt.figure()\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw_networkx(G, pos, font_color = 'white', node_shape = 'o', with_labels = True, node_color='b', edgelist=edges, edge_color=weights, width=3.0, edge_cmap=plt.cm.Blues)\n",
    "    sorted_weights = sorted(weights)\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    fig.subplots_adjust(bottom=0.5)\n",
    "    cmap = plt.cm.Blues\n",
    "    bounds = np.arange(-c_num,1)\n",
    "    norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "        cax=ax,\n",
    "        boundaries=bounds,\n",
    "        ticks=bounds,\n",
    "        spacing='proportional',\n",
    "        orientation='horizontal',\n",
    "        label= 'Log scale',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_graph_with_thresh(best_vech_L, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1973a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4850ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vech_L = np.load('best_vech_L_sparse_opminres-l-d_160_40_40.npy')\n",
    "print(best_vech_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660b2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
